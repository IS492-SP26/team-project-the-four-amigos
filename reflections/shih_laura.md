# METAGPT: META PROGRAMMING FOR A MULTI -AGENT COLLABORATIVE FRAMEWORK

full citation: Hong, S., Zhuge, M., Chen, J., Zheng, X., Cheng, Y., Wang, J., ... & Schmidhuber, J. (2023, August). MetaGPT: Meta programming for a multi-agent collaborative framework. In The twelfth international conference on learning representations.

link: https://openreview.net/forum?id=VtmBAGCN7o&utm_source=chatgpt.com

Summary: 
This paper proposes MetaGPT, a multi-agent framework that organizes LLM agents using Standard Operating Procedures. 
The key idea is that instead of loosely chaining LLM outputs, the system assigns agents structured roles, for example Product Manager, Architect, Engineer,
and forces them to communicate through structured artifacts like design docs, and code specs. 
This reduces hallucination cascades and improves collaboration consistency. 
The framework also introduces structured communication protocols and executable feedback loops to improve task success rates. 
Experimentally, MetaGPT achieves strong performance on software generation benchmarks compared to other multi-agent systems. 
The results suggest that structured workflows are critical for scaling multi-agent reasoning in complex tasks.

Insight I learned:
- Structured intermediate artifacts are key to reducing hallucination. The idea that agents must output PRDs, design docs, or interface specs before moving forward is very powerful.
It basically turns LLM reasoning into something closer to engineering pipeline instead of chat reasoning.
- Instead of inventing new AI workflows, they copied real company structure.
This made me realize real-world systems already solved coordination problems — AI can inherit that.
- Before reading this, I thought multi-agent is just generated by giving prompt.
This paper shows real power comes from workflow, output structure, SOP constraints, not just role identity.


Limitations:
- Heavy dependence on predefined workflow design
The system still depends on humans defining SOP and role responsibilities.
If workflow design is wrong, system performance may degrade.
- The paper shows strong results in software generation tasks, but it’s unclear how well this transfers to messy real-world decision domains like business or market planning.

Idea:
- This paper directly supports using specialized business agents with structured outputs, for example, 
Instead of generic Business AI Agent, we can design market analysis agent, finance agent, operation sgent to work together and make business decision more reliable.

#  Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration
full citation: Zhang, Y., Yang, S., Bai, C., Wu, F., Li, X., Li, X., & Wang, Z. (2024). Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration. Annual Meeting of the Association for Computational Linguistics.

link: https://www.semanticscholar.org/paper/Towards-Efficient-LLM-Grounding-for-Embodied-Zhang-Yang/e1b62c7ee4e22ab63e3b0c9968563e6675833e36

Summary: This paper focuses on improving multi-agent LLM collaboration efficiency using Reinforced Advantage Feedback (ReAd). 
The key problem is that current multi-agent systems rely heavily on self-reflection or environmental feedback, 
which leads to inefficient planning and excessive LLM queries. The authors introduce a reinforcement-learning-inspired advantage function 
that helps agents evaluate whether actions contribute to final task success. This allows agents to refine plans more efficiently and coordinate more effectively. 
Experiments show improved success rates and reduced interaction cost compared to baseline methods. 
The main contribution is providing a more principled feedback mechanism for multi-agent planning instead of heuristic trial-and-error loops.

Insight I learned:
- Feedback quality matters more than feedback frequency
- Multi-agent coordination needs shared objective scoring. The advantage function idea suggests agents need shared evaluation signals for team-level success.
This feels very relevant for business planning, where decisions affect multiple domains simultaneously.
- Many agent papers focus only on correctness, but real-world systems must also minimize compute and decision latency.

Limitations:
- Requires training or learning feedback signals, but in real business environments, defining advantage functions may be difficult.
- It is unclear how directly this translates to abstract domains like market strategy or business feasibility.

Idea:
The paper inspires me thinking that we could design a business feasibility scoring layer, where agents propose decisions, system evaluates using weighted metrics,
agents refine plans based on score.
